# AI_service_LLM/chatbot/agents/history_agent.py

from __future__ import annotations

from typing import List, Dict

from ..core.state import ChatState
from ..core.tracing import traceable
from ..core.prompts import HISTORY_SYSTEM_PROMPT
from ..core.llm import call_llm
from ..core.chat_repository import get_recent_logs


@traceable(name="history_agent")
def run(state: ChatState) -> ChatState:
    """
    ì‚¬ìš©ìì˜ 'ê³¼ê±° ì±—ë´‡ ëŒ€í™” ê¸°ë¡(chat_log / chat_session)'ì„ ê¸°ë°˜ìœ¼ë¡œ
    ìš”ì•½í•˜ê±°ë‚˜ ë‹¤ì‹œ ì„¤ëª…í•´ì£¼ëŠ” ì—ì´ì „íŠ¸.

    ì˜ˆ:
        - "ìµœê·¼ì— ë„ˆë‘ ë¬´ìŠ¨ ëŒ€í™” í–ˆëŠ”ì§€ ìš”ì•½í•´ì¤˜"
        - "ì§€ë‚œë²ˆì— ê³ í˜ˆì•• ì•½ ì„¤ëª…í•´ì¤€ ê±° ë‹¤ì‹œ ì•Œë ¤ì¤˜"
    """
    user_id = state.get("user_id")
    user_message = state["messages"][-1]["content"]

    # 1) ìµœê·¼ ëŒ€í™” ê¸°ë¡ Nê°œ ì¡°íšŒ
    logs: List[Dict] = get_recent_logs(user_id=user_id, limit=20)

    if not logs:
        # ê³¼ê±° ê¸°ë¡ì´ ì—†ìœ¼ë©´ ê·¸ëŒ€ë¡œ ì•ˆë‚´
        answer = (
            "í˜„ì¬ ì €ì¥ëœ ì´ì „ ëŒ€í™” ê¸°ë¡ì´ ì—†ì–´ì„œ, ê³¼ê±° ëŒ€í™”ë¥¼ ì°¸ê³ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. "
            "ì§ˆë¬¸ì„ ë‹¤ì‹œ êµ¬ì²´ì ìœ¼ë¡œ ë§ì”€í•´ ì£¼ì‹œë©´, ìƒˆë¡œìš´ ì§ˆë¬¸ìœ¼ë¡œ ë‹µë³€í•´ ë“œë¦´ê²Œìš”."
        )

        # ğŸ”¥ state ê°’ ì±„ìš°ê¸°
        state["answer"] = answer
        state["sources"] = []  # history agentëŠ” ì¶œì²˜ê°€ ì—†ë‹¤

        # state.messages append
        state["messages"].append(
            {
                "role": "assistant",
                "content": answer,
                "meta": {"agent": "history_agent", "log_count": 0},
            }
        )
        return state

    # 2) context ë¬¸ìì—´ë¡œ ë³€í™˜
    history_lines: List[str] = []
    for log in logs:
        created_at = log.get("created_at", "")
        # datetime ê°ì²´ì¼ ìˆ˜ë„ ìˆìœ¼ë‹ˆ ë¬¸ìì—´ë¡œ ìºìŠ¤íŒ…
        if hasattr(created_at, "isoformat"):
            created_at_str = created_at.isoformat()
        else:
            created_at_str = str(created_at)

        session_id = log.get("session_id", "")
        role = log.get("role", "user")
        content = log.get("content", "")

        # ê° ë©”ì‹œì§€ë¥¼ í•œ ì¤„ì”© ê¸°ë¡
        history_lines.append(
            f"[ì„¸ì…˜ {session_id} | {created_at_str} | {role}]\n"
            f"{role}: {content}"
        )

    history_context = "\n\n".join(history_lines)

    # 3) LLM í˜¸ì¶œ (ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ + ê³¼ê±° ê¸°ë¡ ì»¨í…ìŠ¤íŠ¸ ì œê³µ)
    answer = call_llm(
        system_prompt=HISTORY_SYSTEM_PROMPT,
        user_message=user_message,
        context=history_context,
    )

    # 4) state.messages append
    state["messages"].append(
        {
            "role": "assistant",
            "content": answer,
            "meta": {
                "agent": "history_agent",
                "log_count": len(logs),
            },
        }
    )

    # ğŸ”¥ ìµœì¢… ë°˜í™˜ìš© í•„ë“œ
    state["answer"] = answer
    state["sources"] = []  # history agentëŠ” ì™¸ë¶€ ë¬¸ì„œ RAGê°€ ì•„ë‹ˆë¯€ë¡œ í•­ìƒ ë¹ˆ ë¦¬ìŠ¤íŠ¸

    return state
